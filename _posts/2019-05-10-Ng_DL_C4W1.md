---
layout: post
title: Deep Learning by Andrew (八) 卷积神经网络基础
category: 笔记
tags: 
  - deep learning
---


<style>
img{
    width: 60%;
    padding-left: 20%;
}
</style>

## 1. 计算机视觉

计算机视觉 (computer vision) 包含很多不同的类别的问题,如图片分类,目标检测与追踪,图片风格迁移等等:



![][1]

对于小尺度的图片,也许可以用深度神经网络便可以解决,但由于DNN不能很好的利用图片中像素点的空间位置关系,从而导致性能上与人类的贝叶斯概率相去甚远. 同时,当图片的尺寸特别大时,DNN的网络结构将会变得非常庞大,使用时有太多的参数需要学习,从而使得DNN不再适用.

此时,卷积神经网络 (CNN)在计算机视觉问题上是一个很好的网络结构



## 2. 边缘检测与卷积

在传统的图像处理算法中,卷积操作非常的常见,如图像的降噪,边缘提取检测等等.同时,人眼在观察世界时,通常对噪声有一定的鲁棒性,且人眼通常对物体的边缘非常敏感,用卷积来实现一些高层次的感知问题,一定程度上符合了人眼的环境感知策略.下面将会从边缘检测展开,对卷积操作进行一定的解释:

![][2]



传统的边缘检测算法,大多基于垂直边缘检测和水平边缘检测的结合,检测算法中,对一张图片;用一个 $3 \times 3$ 大小的 **filter** 进行卷积运算,以水平边缘检测为例,如下图所示:

![][3]



实际上是在针对不同的方向进行梯度计算,一些改进的 filter 会对卷积核中的参数进行一定的变化.对于复杂的算法要求,当我们难以直观的设计出所需要的卷积核时,我们可以直接将 **filter** 的参数当做学习的目标,通过反向传播算法,学习到所需要的 **filter** 的参数,这就是卷及神经网络的主题思想

**卷积和互相关**

在数学定义上,矩阵的卷积 (convolution) 操作需要先将卷积核在水平和垂直方向上进行翻转,构成卷积核的镜像,然后再用词镜像与前面的矩阵进行移动相乘求和操作,但是在深度学习中,由于卷积核的参数本身就是学习的目标,是否翻转也就不再重要了,所以会直接进行移动相乘求和,这种卷及操作在数学上准确的来说被称为**互相关** (cross-correlation)



## 3. 卷积网络

#### 3.1 边缘填充 (Padding)

在上一节中;我们发现,原始的卷积操作存在着一定的弊端:

- 每进行一次卷积,图片的尺寸就会一定程度上缩小
- 边缘和角落的像素进行卷积运算的次数少,可能会丢失掉有用的信息

为了解决上面两个缺点,我们在进行卷积运算前为图片加上padding, 包围角落和边缘的像素，使得通过filter的卷积运算后，图片大小不变，也不会丢失角落和边沿的信息:

![][4]

padding一般有 **valid** 和 **same** 两种,设定图片的尺寸是 $n \times n$, filter 的大小是 $f$, padding 的大小是 $p$,:

- valid, no padding, $(n \times n) \to (n-f+1 \times n-f+1) $
- same, 输入与输出的图片大小相同, $(n \times n) \to (n \times n), p = (f+1)/2$



#### 3.2 卷积步长 (Stride)

卷积步长代表卷积运算的步长:

![][5]

以 $s$ 代表卷积的步长,图片尺寸的变化为:


$$
n \times n \to \lfloor \frac{n+2p-f}{s} +1 \rfloor  \times \lfloor \frac{n+2p-f}{s} +1 \rfloor
$$


#### 3.3 立体卷积

对于灰度图像,卷积核与图像均是二维的,但在RGB图像中,因为图片有三通道,所以卷积核也应该是三维的:

![][6]

单个卷积核应用于图片时，提取图片特定的特征，不同的卷积核提取不同的特征。如两个大小均为 ￼ 的卷积核分别提取图片的垂直边缘和水平边缘。



#### 3.4 多维卷积

单个卷积可用于提取图片的某一特征,但通常我们需要提取不同的特征,所以我们针对同一图片会用多个不同的卷积核进行卷积运算:

![][7]





#### 3.5 简单的卷积网络

和普通的神经网络单层前向传播一样,卷积神经网络也是先有输如和权重及偏置做线性运算,然后将得到的结果输入到激活函数之中:

- ​	$z^{[l]} = w^{[l]} a^{[l-1]} + b^{[l]}$
-  $z^{[l]} = g(z^{[l]})$



若针对RGB图像,卷积核的大小为3,则单层单个卷积核的参数大小为: $ (3 \times 3 \times 3 +1) = 28$



#### 3.6池化 (pooling)

使用 stride 为1的卷积操作,且进行了 same padding 之后可以保持图像的大小不变,但如果整个网络中,图片的大小一直不变,则仍然会导致模型过于复杂.同时,进行特征提取的时候,有一些提取出来的特征有一些不明显的特征应该予以舍去来提升模型的鲁棒性,所以就发展出了池化技术,主要的池化包括 **max pooling** 和 **average pooling**



![][8]



![][9]

同样,池化也是卷积操作,也存在 padding, filter size 和 stride 的选择,层与层之间大小的变化与之前的卷积操作一致:
$$
n \times n \to \lfloor \frac{n+2p-f}{s} +1 \rfloor  \times \lfloor \frac{n+2p-f}{s} +1 \rfloor
$$



#### 3.7 LeNet-5

如下是经典网络 leNet-5 的示意图 (注: 原课件中的示意图和后续的参数之间的匹配有点问题,所以这里的直接用了LeNet-5,图片来自[李宏毅老师的课件](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html)):

![][10]



其特点如下:

- 随着网络的深入,提取的特征图片大小逐渐减小,但通道数量随之增加
- 网络结构为 conv -- pool -- conv -- pool -- Fc -- Fc -- Fc --softmax 



具体的结构参数如下:

|                 | Activation shape | Activation size | parameters |
| :-------------: | :--------------: | :-------------: | :--------: |
|      Input      |    (32,32,1)     |      3,072      |     0      |
| Conv1 (f=5,s=1) |    (28,28,6)     |      6,272      |    208     |
|      Pool1      |    (14,14,6)     |      1,568      |     0      |
| Conv2 (f=5,s=1) |    (10,10,16)    |      1600       |    416     |
|      Pool2      |     (5,5,16)     |       400       |     0      |
|       Fc        |     (400,1)      |       400       |     0      |
|       Fc3       |     (120,1)      |       120       |   48,001   |
|       Fc4       |      (84,1)      |       84        |   10,081   |
|     Softmax     |      (10,1)      |       10        |    841     |



#### 3.8 为什么使用卷积神经网络

与普通的深度神经网络相比,卷积神经网络有着如下的优点:

- **参数少**, 由于进行了卷积操作,使得卷积层之间的连接所需参数非常少
- **参数共享**, 一个特征检测器（filter）对图片的一部分有用的同时也有可能对图片的另外一部分有用
- **连接的稀疏性**：在每一层中，每个输出值只取决于少量的输入



## 4. 代码实现

以下代码为下图所示的深层神经网络的实现，所用网络结构参考自吴恩达的Deep Learning课程作业，并不是作业的答案，仅作加深理解和记忆之用，**希望仍在上课的学生能够独立完成代码** 

使用 Tensorflow 搭建模型的大致步骤如下:

- create placeholders
- initialize parameters
- forward propagate
- compute the cost
- create an optimizer

```python
# 所需库
import math
import numpy as np
import h5py
import matplotlib.pyplot as plt
import scipy
from PIL import Image
from scipy import ndimage
import tensorflow as tf
from tensorflow.python.framework import ops
from cnn_utils import *

# TF需要创建holder来喂数据,用 None 来定义不知道的数据大小
def create_placeholders(n_H0, n_W0, n_C0, n_y):
    X = tf.placeholder(tf.float32, shape = (None, n_H0, n_W0, n_C0))
    Y = tf.placeholder(tf.float32, shape = (None, n_y))
    return X, Y
  
# TF用于初始化参数
def initialize_parameters():
    W1 = tf.get_variable('W1', [4, 4, 3, 8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))
    W2 = tf.get_variable('W2', [2, 2, 8, 16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))

    parameters = {"W1": W1,
                  "W2": W2}
    
    return parameters

# 定义前向传播
def forward_propagation(X, parameters):
    
    # Retrieve the parameters from the dictionary "parameters" 
    W1 = parameters['W1']
    W2 = parameters['W2']
    
    # CONV2D: stride of 1, padding 'SAME'
    Z1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding="SAME")
    # RELU
    A1 = tf.nn.relu(Z1)
    # MAXPOOL: window 8x8, sride 8, padding 'SAME'
    P1 = tf.nn.max_pool(A1, ksize=[1,8,8,1], strides=[1,8,8,1], padding="SAME")
    # CONV2D: filters W2, stride 1, padding 'SAME'
    Z2 = tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding="SAME")
    # RELU
    A2 = tf.nn.relu(Z2)
    # MAXPOOL: window 4x4, stride 4, padding 'SAME'
    P2 = tf.nn.max_pool(A2, ksize=[1,4,4,1], strides=[1,4,4,1], padding="SAME")
    # FLATTEN
    P2 = tf.contrib.layers.flatten(P2)
    # FULLY-CONNECTED without non-linear activation function (not not call softmax).
    # 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" 
    Z3 = tf.contrib.layers.fully_connected(P2, 6, activation_fn=None)

    return Z3

# 定义损失函数, reduce_mean用于计算元素的均值
def compute_cost(Z3, Y):
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))
    return cost
  
# 建立模型
def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,
          num_epochs = 100, minibatch_size = 64, print_cost = True):

    ops.reset_default_graph()
    (m, n_H0, n_W0, n_C0) = X_train.shape             
    n_y = Y_train.shape[1]                            
    seed = 3
    costs = []
    
    # Create Placeholders of the correct shape
    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)
    # Initialize parameters
    parameters = initialize_parameters()
    # Forward propagation: Build the forward propagation in the tensorflow graph
    Z3 = forward_propagation(X, parameters)
    # Cost function: Add cost function to tensorflow graph
    cost = compute_cost(Z3, Y)
    # Backpropagation, define optimization function
    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)
    # Initialize all the variables globally
    init = tf.global_variables_initializer()
     
    # Start the session to compute the tensorflow graph
    with tf.Session() as sess:
        # Run the initialization
        sess.run(init)
        
        # Do the training loop
        for epoch in range(num_epochs):

            minibatch_cost = 0.
            num_minibatches = int(m / minibatch_size) 
            seed = seed + 1
            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)

            for minibatch in minibatches:
                # Select a minibatch
                (minibatch_X, minibatch_Y) = minibatch
                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})
                minibatch_cost += temp_cost / num_minibatches
                
            # Print the cost every epoch
            if print_cost == True and epoch % 5 == 0:
                print ("Cost after epoch %i: %f" % (epoch, minibatch_cost))
            if print_cost == True and epoch % 1 == 0:
                costs.append(minibatch_cost)
        
        # plot the cost
        plt.plot(np.squeeze(costs))
        plt.ylabel('cost')
        plt.xlabel('iterations (per tens)')
        plt.title("Learning rate =" + str(learning_rate))
        plt.show()
        # Calculate the correct predictions
        predict_op = tf.argmax(Z3, 1)
        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))
        # Calculate accuracy on the test set
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
        print(accuracy)
        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})
        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})
        print("Train Accuracy:", train_accuracy)
        print("Test Accuracy:", test_accuracy)
                
        return train_accuracy, test_accuracy, parameters
```






[1]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/CV_tasks.jpg
[2]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/conv_compute.jpg
[3]: https://res.cloudinary.com/bxy1994/image/upload/v1557481372/DL_coursera/edge_detect.jpg
[4]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/padding.jpg
[5]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/stride.jpg
[6]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/conv_filter.jpg
[7]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/multi_filter.jpg
[8]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/pooling_max.jpg
[9]: https://res.cloudinary.com/bxy1994/image/upload/v1557479965/DL_coursera/pooling_average.jpg
[10]: https://res.cloudinary.com/bxy1994/image/upload/v1557491940/DL_coursera/cnn_lenet5.png