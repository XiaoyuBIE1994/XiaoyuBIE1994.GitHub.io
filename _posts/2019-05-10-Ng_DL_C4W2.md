---
layout: post
title: Deep Learning by Andrew (九) 卷积神经网络案例学习
category: 笔记
tags: 
  - deep learning
---


<style>
img{
    width: 60%;
    padding-left: 20%;
}
</style>





## 1. 经典的卷积神经网络



 #### 1.1 LeNet-5

LeNet-5的任务最初被用于识别手写数字，在1998年由Yann Le Cun提出，这一网络中并没有用到padding来保持图片大小，并且训练于 $32 \times 32 \times 1$ 的灰度图上

![][1]

网络的主要结构为:

Conv -- Avg pool -- Conv -- Avg pool -- Fc -- Fc -- Softmax

在今天看来这只是一个小型的网络，**参数大概60,000左右**，最后的softmax输出了识别0到9的概率。原始的论文中，激活函数采用了 sigmoid 和 tanh，而不是现在主流的 ReLu， 而且原文在池化层后也进行了非线性的处理。由于当时计算机算力的限制,原始的LeNet-5让每个滤波器处理不同的通道 (现在网络中一个滤波器会处理所有的通道)。同时，原文中还介绍了其他的内容 (如现在已经不常用的图转换网络GTN)，关于LeNet-5的介绍主要集中在第二章和第三章



原论文: [LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)



#### 1.2 AlexNet

AlexNet直接对彩色图进行处理,如下:

![][2]

网络的特点如下：

- 与LeNet相似，但网络结构更大，参数更多，表现更加出色，拥有大概**六千万个参数**
- 使用了Relu
- 使用了多个GPUs，每个GPU负责训练一部分训练，GPU之间有通讯（受限于当时GPU的计算力）
- LRN（Local Response Normalization，在某一个层中，对一个像素点的所有通道进行归一化处理后来发现用处不大，丢弃了）



原文比较容易懂，推荐阅读 =， =

原文: [Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)



#### 1.3 VGG-16

VGG网络的特点是简单，网络中没有设置过多的超参，一直使用大小 $3\times 3$的filter (stride=1, same pidding)，池化层均选用 Max pooling (size $2 \times 2$, stride=2)，VGG-16中的16指的是网络中包含着16个带有参数权重的层 ($2 \times 2 + 3 \times 3 + 3 = 16$ )



![][3]

网络的特点如下：

- 结构非常简单
- 参数非常多，为**1亿3千8百万**



原文： [Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.](https://arxiv.org/pdf/1409.1556.pdf%20http://arxiv.org/abs/1409.1556.pdf)



## 2. ResNet

深度神经网络非常难以训练，因为会遇到梯度消失和梯度爆炸的问题，而 ResNet 中使用了跳跃连接 (skip connection)，它能让你从一层中得到激活，并且突然传递到下一层，甚至更深的神经网络层。

普通的神经网络模块的前向传播过程为： $a^{[l+1]} = g(w^{[l+1]} a^{[l]} + b^{[l+1]})$

而 ResNet 则在传播过程中增加了一个从 $a^{[l]} $ 到 $z^{[l+2]}$ 的链接，也就是 "short cut/skip connection"，此时的传播函数变为：$a^{[l+2]} = g(z^{[l+2]} + a^{[l]} )$

![][4]

这里传统的神经网络就变成了一个**残差块**，多个残差块堆积就够了**残差网络 (ResNet)**

![][5]

没有残差模块时，由于梯度消失/爆炸 (vanishing/exploding)，当网络层数过高时，训练误差不仅没有继续下降，然而升高了，但加入了残差模块后，即使网络再深，训练误差都能继续减小：

![][6]

 

**ResNet 表现好的原因**

假设有一个比较大的神经网络，第 $l$ 层的输出为 $a^{[l]}$， 我们在此处加上一个残差块：



![][7]

为了简便起见，假设网络的激活函数为 Relu， 则有 $a \ge 0$

此时第 $l+2$ 层的输出为：


$$
a^{[l+2]} = g(W^{[l+1]} a^{[l+1]} + b^{[l+1]} + a^{[l]})
$$

加入我们使用的是 $L_2$ 正则化，则网络的参数会不断的减小，最后使得 $W^{[l+1]} a^{[l+1]} + b^{[l+1]}$ 趋近于0，此时输出变为：

$$
a^{[l+2]} = g(a^{[l]}) = a^{[l]}
$$

此时我们在网络中重新得到了第 $l$ 层的输出，这使得残差网络能够更容易学习到恒等的结构，当网络的结构足够深时，残差网络能够至少保证网络的性能不会下降，甚至还因为学习到了新的参数而提升了网络的性能。在实际应用中，当第 $l$ 层的输出和第 $l+2$ 层的输出矩阵维度不同时，为了保证矩阵的正确运算，我们可以使用 $W _s a^{[l]}$  来代替 $a^{[l]}$ 以保持统一的维度



## 3. 1 X 1 卷积

$1 \times 1$ 卷积是指卷积核的大小为1，在二维上相当于图片的每个元素和一个卷积数字相乘，而在三维上则是和一个 $1 \times 1 \times n_c$ 进行卷积，最终会得到一个相同长宽但第三维度变为卷积核个数的图片，如下图：

![][8]



**应用：**

- 维度压缩：当卷积核的个数小于输入数据的第三维度时，实现了维度的压缩
- 增加非线性： 若卷积核的个数等于输入数据的第三维度时，数据维度不变，但增加了模型的非线性



![][9]



## 4. Inception 网络

Inception网络的主要作用是我们不再需要考虑构建深度卷积网络时需要使用多大的卷积核和是否需要添加池化，而是将其全部用上，使用 same 的 padding，最后将结果级联，如下图所示：

![][10]



**计算成本**

在上面的问题中，虽然我们使用不同大小的卷积核来减少超参的调试，但也会增加计算成本，如下图所示：

![][11]

32个 $5 \times 5$ 的 filter 需要大概 120M 次运算，为了降低计算次数，我们可以增加 $1 \times 1$ 的中间层 （也成为 bottleneck layer）：

![][12]

使用了中间层之后，计算次数降低到了 12.4M，是原来的大约十分之一，而且通过合理的设置 bottleneck layer 可是几乎不影响网络的性能



**Inception 模块**

一个 Inception 模块由多个不同大小的卷积以及池化构成，并通过 $1 \times 1$ 来简化计算：

![][13]



多个 Inception 模块堆叠在一起便构成了 Inception Network，如下图所示的 GoogleNet 结构：

![][14]





## 5. 实用建议



- 使用开源代码，因为很多时候超参非常难以调节
- 使用迁移学习，降低训练难度
- 使用数据增强，比如Affine变化，色彩改变 (e.g. PCA color augmentation)



**Tips for doing well in benchmarks:**

- Ensembling, 独立训练若干个网络，取结果的平均值
- Multi-corp, 对测试图片进行少量的不同的剪裁，运行网络取结果的平均值



## 6. 代码实现

以下代码为下图所示的深层神经网络的实现，所用网络结构参考自吴恩达的Deep Learning课程作业，并不是作业的答案，仅作加深理解和记忆之用，**希望仍在上课的学生能够独立完成代码** 

#### 6.1 Keras 入门

```python
'''
Dependencies
'''
import numpy as np
from keras import layers
from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D
from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D
from keras.models import Model
from keras.preprocessing import image
from keras.utils import layer_utils
from keras.utils.data_utils import get_file
from keras.applications.imagenet_utils import preprocess_input
import pydot
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from keras.utils import plot_model
from kt_utils import *

import keras.backend as K
K.set_image_data_format('channels_last')
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

'''
 Data preperation
'''
X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()

# Normalize image vectors
X_train = X_train_orig/255.
X_test = X_test_orig/255.

# Reshape
Y_train = Y_train_orig.T
Y_test = Y_test_orig.T

'''
Model build
Input: shape of images
Output: a Model() instance in Keras
'''
def HappyModel(input_shape):
    X_input = Input(input_shape)
    X = ZeroPadding2D((3,3))(X_input)
    X = Conv2D(32, (7,7), strides = (1,1), name = 'conv0')(X)
    X = BatchNormalization(axis = 3, name = "bn0")(X)
    X = Activation("relu")(X)
    X = MaxPooling2D((2,2), name='max_pool')(X)
    X = Flatten()(X)
    X = Dense(1, activation='sigmoid', name='fc')(X)
    model = Model(inputs = X_input, outputs = X, name='HappyModel')
    return model

'''
Implementation
'''
happyModel = HappyModel(X_train.shape[1:])
# 二分类问题使用交叉熵
happyModel.compile(optimizer = "Adam", loss = "binary_crossentropy", metrics = ["accuracy"])
happyModel.fit(x = X_train, y = Y_train, epochs = 40, batch_size = 16)
preds = happyModel.evaluate(x = X_test, y = Y_test)
print ("Loss = " + str(preds[0]))
print ("Test Accuracy = " + str(preds[1]))

'''
Show model information
'''
# 表格形式，显示每层的信息和参数
happyModel.summary()
# 图表的方式，显示网络架构
plot_model(happyModel, to_file='HappyModel.png')
SVG(model_to_dot(happyModel).create(prog='dot', format='svg'))
```






[1]: https://res.cloudinary.com/bxy1994/image/upload/v1557498138/DL_coursera/LeNet-5.jpg
[2]: https://res.cloudinary.com/bxy1994/image/upload/v1557498138/DL_coursera/AlexNet.jpg
[3]: https://res.cloudinary.com/bxy1994/image/upload/v1557498138/DL_coursera/VGG16.jpg
[4]: https://res.cloudinary.com/bxy1994/image/upload/v1557503349/DL_coursera/ResNet_example.jpg
[5]: https://res.cloudinary.com/bxy1994/image/upload/v1557503064/DL_coursera/ResNet.jpg
[6]: https://res.cloudinary.com/bxy1994/image/upload/v1557503064/DL_coursera/ResNet_compare.jpg
[7]: https://res.cloudinary.com/bxy1994/image/upload/v1559684853/DL_coursera/ResNet_intuition.png
[8]:https://res.cloudinary.com/bxy1994/image/upload/v1559916994/DL_coursera/1x1_filter_1.jpg
[9]:https://res.cloudinary.com/bxy1994/image/upload/v1559916994/DL_coursera/1x1_filter_2.jpg
[10]:https://res.cloudinary.com/bxy1994/image/upload/v1559916994/DL_coursera/Inception_1.jpg
[11]:https://res.cloudinary.com/bxy1994/image/upload/v1559916994/DL_coursera/Inception_2.jpg
[12]:https://res.cloudinary.com/bxy1994/image/upload/v1559916994/DL_coursera/Inception_3.jpg
[13]:https://res.cloudinary.com/bxy1994/image/upload/v1559916994/DL_coursera/Inception_4.jpg
[14]:https://res.cloudinary.com/bxy1994/image/upload/v1559918229/DL_coursera/Inception_5.jpg