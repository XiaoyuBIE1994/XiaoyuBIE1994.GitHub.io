---
layout: post
title: Deep Learning by Andrew (七) 机器学习策略(下)
category: 笔记
tags: 
  - deep learning
---


<style>
img{
    width: 60%;
    padding-left: 20%;
}
</style>



## 1. 误差分析

当我们在训练一些模型的时候,比如一个猫和狗的分类模型,最终得到了90%的精确度,也就是10%的错误率,这个时候就需要对模型进行一定的调整来提升性能.但如果不加分析的去做,可能几个月的努力都不会有结果,所以一个好的误差分析流程非常重要



#### 1.1 错误样本分析

我们可以在开发集(测试集)上选取100个猫被误分类的例子,统计有多少个被分成了狗,这时会有如下两种情况:

- 一种情况是只有5个样子是狗,如果我们针对狗的来进行优化,可以提升的上线就是5%,也就是达到9.5%的错误率,这时被称为性能上限,这种情况下这个方向的努力就并不值得了
- 另一种情况是50个样子是狗,这时针对狗的优化就会很好的增加模型的性能,因为此时的性能上限是5%的错误率



#### 1.2 并行分析

当同时有多个idea对模型进行优化时,可以建立统计表格来进行分析,例如idea如下:

- 解决猫被误识为狗
- 解决大型猫科动物被误识别的问题
- 提升模糊图片的质量

此时我们可以建立如下表格统计错误类型的百分比,显然针对狗的优化就显得非常不值得

|   Image   |   Dog    | Great Cat | Blurring |          Comments          |
| :-------: | :------: | :-------: | :------: | :------------------------: |
|     1     | $\surd$  |           |          |          pitbull           |
|     2     |          |           | $\surd$  |                            |
|     3     |          |  $\surd$  | $\surd$  | lion in the zoo, rainy day |
| $\vdots$  | $\vdots$ | $\vdots$  | $\vdots$ |                            |
| % of toal |    8%    |    43%    |   61%    |                            |



#### 1.3 清楚误标记

有时在对样本进行标记的时候,会出现误标记的情况.一般来说,深度学习模型对于**随机误差**有着很强的鲁棒性,即使有一部分样本被误标记也不会过多影响实验结果,但是DL模型对于**系统误差**(如某个人一直把白色的狗标记成猫)就没有那么好的效果了.我们可以在并行分析中加入误分类这一项进行分析:

- 如果误标记占比较小,可优先优化其他项,等到占比较高时再进行优化
- 在dev/test集上进行同样的统计,确保他们来自同一分布(train集可以和dev/test的分布不完全相同)
- 不仅检查错误分类的例子,有时也需要虑正确分类的例子



## 2.快速搭建系统



对于一个新的项目,最开始不要考虑的过于复杂,应该先快速搭建出一个基本的系统,进行迭代



## 3. 不同分布的问题



#### 3.1 训练和测试数据的不同分布



假设我们在网上找到了20万张清晰的图片进行分析,但我们实际需要测量的是用户用手机拍摄时的准确度,但手机上的照片数量不足 (只有1万张),而且照片的质量参差不齐,此时训练集和测试集不是在同一分布.

**方法一**

将21万张照片加在一起，重新分配

- 优点, 三个集合中的数据保持了一致的分布
- 缺点, dev 集的目的是用于瞄准目标,而现在目标中的绝大多数成为了优化网络上的高清晰图片,不符合原始目的

**方法二**

用20万张网络照片加上5000张手机用户拍摄的照片最为训练集,剩下的5000张手机照片均分为验证集和测试集

- 优点, dev 集上的所有图片都是手机图片,模型的优化全部针对原始目标
- 缺点, train 集和 dev/test 集来自不同的分布

**Notation**

从长期来看,方法二能够带来更好的系统性能



#### 3.2. 不同分布的偏差和方差

通过估计学习算法的偏差和方差，可以帮助我们确定接下来应该优先努力的方向。但是当我们的训练集和开发、测试集来自不同的分布时，分析偏差和方差的方式就有一定的不同,这是因为 train 集和 dev/test 集的分布不同导致的,此时我们应该:

- 设置**训练开发集 (train-dev set)**, train-dev 集来自于 train 集的随机抽样,用于和训练误差和dev误差的比较,若train-dev error 和 train error 差别很大,说明模型的**过拟合**,**泛化能力不够**,若train-dev error 和 train error 差别不大但和 dev error 差别很大,则说明是**分布不匹配**的问题
- **分布不同的偏差方差分析**, 通过观察 Human level、Training set error、Training-dev set error、Dev error、Test error, 可以分别判断模型是否需要在可避免的偏差、方差、数据分布不匹配、开发集的拟合程度上进行改进



#### 3.3. 不同分布的解决办法

如果通过上一节的误差分析，我们可以得知，模型最终在开发和测试集上的误差最终是由于数据分布不匹配而导致。那么这种情况下应该进行如下处理:

- 进行人工误差分析，尝试去了解训练集和开发测试集的具体差异 (例如噪音)
- 尝试把训练数据变得更像 dev 集, 或者收集更多 dev/test 集的数据(人工数据合成,如添加噪声等)



## 4. 多类型的数据的学习



#### 6.1 迁移学习 (transfer learning)

迁移学习主要针对于如下场景, 我们对于任务A有着非常多的数据,但对于任务B只有少部分的数据,此时我们可以先针对任务A进行预训练,然后将网络的最后一层拿掉,用若干层初始网络代替,然后用替换后的网络针对任务B进行训练.这是因为当任务A和任务B有着很多类似之处时 (如任务A是分类猫狗,任务B是对医疗的X光片进行分类),网络的前面几层多用于提取一些低层次的特征 (如边缘,角点等等),这些需求在两个任务中是等价的,所以我们便可以利用任务A中的数据针对任务B进行预训练 (pre-training)

![][1]



**Notation**

迁移学习一般只有满足如下要求才有意义:

- 任务A和任务B有着相同的输入 (音频,图像)
- 任务A的数据量远大于任务B
- 来自任务A的低层特征对于任务B是有用的





#### 6.2 多任务学习

当一个网络需要有多个输出时,比如计算机视觉中的目标检测,我们可以使用多任务学习的方法:



![][2]

该任务中的损失函数定义如下:


$$
loss = \frac{1}{m} \sum_{i=1}^m \sum_{j=1}^4 L(\hat{y}_j^{(i)}, y_j^{(i)})
$$
当我们的标注数据中有一部分没有完全标记时 (例如有4个检测目标,但标注了2个), 可以在计算 loss 是只针对被标记的目标



**Notation**

多任务一般只有满足如下要求才有意义:

- 在多任务中低层次的特征是可以共享的
- 每一个任务所拥有的数据量大体相当
- 需要训练一个足够大的网络来保证每一个单一任务的精度



## 5. 端到端学习

**定义：**

传统的数据处理或学习模型包含了多个阶段的处理过程，而端到端的深度学习则忽略了这些阶段，用单个神经网络来替代



**优点:**

- 让数据起到了主导作用
- 所需的手工设计的组件更少



**缺点:**

- 需要大量的数据
- 丢弃了可能有用的手工组件



**Notation**

- 是否应用端到端学习取决于是否有足够的数据能够学习到从**x**直接映射到**y**的复杂函数





[1]:https://res.cloudinary.com/bxy1994/image/upload/v1557402200/DL_coursera/transfer_learning.jpg
[2]: https://res.cloudinary.com/bxy1994/image/upload/v1557404254/DL_coursera/multi_task_learning.jpg